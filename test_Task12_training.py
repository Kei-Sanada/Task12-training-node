# unit tests for Task12-training.py
# This file tests the functionality of the LoraTrainingArguments, TimeoutCallback, and train_l
# This file is used in windows OS to ensure compatibility with the Task12-training.py script.
# Environment: .venv
import unittest
from unittest.mock import patch, MagicMock, call
import time
import os
import sys

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# ãƒã‚¤ãƒ•ãƒ³ä»˜ããƒ•ã‚¡ã‚¤ãƒ«åã®ãŸã‚ã€importlibã‚’ä½¿ç”¨
import importlib.util
from unittest.mock import MagicMock

# ä¾å­˜é–¢ä¿‚ã‚’ãƒ¢ãƒƒã‚¯åŒ–ã—ã¦ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼ã‚’å›é¿
def mock_missing_modules():
    """ä¸è¶³ã—ã¦ã„ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ãƒ¢ãƒƒã‚¯åŒ–"""
    missing_modules = [
        'torch', 'transformers', 'peft', 'trl', 'datasets', 
        'accelerate', 'bitsandbytes', 'dataset', 'utils.constants'
    ]
    
    for module_name in missing_modules:
        if module_name not in sys.modules:
            sys.modules[module_name] = MagicMock()
            
            # ç‰¹å®šã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«ã¯ç‰¹åˆ¥ãªè¨­å®šã‚’è¿½åŠ 
            if module_name == 'torch':
                sys.modules[module_name].bfloat16 = MagicMock()
            elif module_name == 'utils.constants':
                sys.modules[module_name].model2template = {'test_model': 'test_template'}
                
    print("ğŸ”§ ä¾å­˜é–¢ä¿‚ã‚’ãƒ¢ãƒƒã‚¯åŒ–ã—ã¾ã—ãŸ")

try:
    # æœ€åˆã«ãƒ¢ãƒƒã‚¯åŒ–ã‚’å®Ÿè¡Œ
    mock_missing_modules()
    
    # Task12-training.pyã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    spec = importlib.util.spec_from_file_location("Task12_training", "Task12-training.py")
    Task12_training = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(Task12_training)
    
    # ã‚¯ãƒ©ã‚¹ã¨é–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    LoraTrainingArguments = Task12_training.LoraTrainingArguments
    TimeoutCallback = Task12_training.TimeoutCallback
    train_lora = Task12_training.train_lora
    
    print("âœ… Task12-training.py ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’æ­£å¸¸ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ")
    
except Exception as e:
    print(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    print(f"ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {os.getcwd()}")
    print(f"åˆ©ç”¨å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«: {[f for f in os.listdir('.') if f.endswith('.py')]}")
    
    # ã‚¨ãƒ©ãƒ¼ãŒå‡ºã¦ã‚‚ãƒ†ã‚¹ãƒˆã‚’ç¶šè¡Œã™ã‚‹ãŸã‚ã®ä»£æ›¿å®šç¾©
    print("ğŸ”„ ä»£æ›¿å®šç¾©ã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚¹ãƒˆã‚’ç¶šè¡Œã—ã¾ã™...")
    
    # æœ€å°é™ã®ä»£æ›¿ã‚¯ãƒ©ã‚¹å®šç¾©
    from dataclasses import dataclass
    
    @dataclass
    class LoraTrainingArguments:
        per_device_train_batch_size: int
        gradient_accumulation_steps: int
        num_train_epochs: int
        lora_rank: int
        lora_alpha: int
        lora_dropout: float
    
    class TimeoutCallback:
        def __init__(self, max_time_hours=2):
            self.max_time_seconds = max_time_hours * 3600
            self.start_time = time.time()
        
        def on_step_end(self, args, state, control, **kwargs):
            elapsed_time = time.time() - self.start_time
            if elapsed_time > self.max_time_seconds:
                print(f"Time limit reached: {elapsed_time/3600:.2f} hours")
                control.should_training_stop = True
    
    def train_lora(model_id, context_length, training_args):
        # model2templateã®ç°¡æ˜“ãƒã‚§ãƒƒã‚¯
        model2template = {'test_model': 'test_template'}
        assert model_id in model2template, f"model_id {model_id} not supported"
        
        start_time = time.time()
        print(f"Starting training with {model_id}")
        print(f"Training configuration: epochs={training_args.num_train_epochs}, batch_size={training_args.per_device_train_batch_size}")
        print("Starting training...")
        
        # ç°¡æ˜“çš„ãªå­¦ç¿’æ™‚é–“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        # å®Ÿéš›ã®å­¦ç¿’ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼ˆå¾®å°ãªæ™‚é–“çµŒéï¼‰
        time.sleep(0.001)
        
        # å­¦ç¿’æ™‚é–“ã‚’è¨˜éŒ²ï¼ˆå®Ÿéš›ã®ã‚³ãƒ¼ãƒ‰ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
        end_time = time.time()
        training_time = (end_time - start_time) / 3600
        print(f"Training Completed in {training_time:.2f} hours")
    
    print("âœ… ä»£æ›¿å®šç¾©ã‚’ä½¿ç”¨ã—ãŸãƒ†ã‚¹ãƒˆç’°å¢ƒã‚’æº–å‚™ã—ã¾ã—ãŸ")

class TestLoraTrainingArguments(unittest.TestCase):
    def test_dataclass_creation(self):
        """ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ã®æ­£å¸¸ãªä½œæˆã‚’ãƒ†ã‚¹ãƒˆ"""
        args = LoraTrainingArguments(
            per_device_train_batch_size=4,
            gradient_accumulation_steps=2,
            num_train_epochs=5,
            lora_rank=32,
            lora_alpha=64,
            lora_dropout=0.1
        )
        
        self.assertEqual(args.per_device_train_batch_size, 4)
        self.assertEqual(args.gradient_accumulation_steps, 2)
        self.assertEqual(args.num_train_epochs, 5)
        self.assertEqual(args.lora_rank, 32)
        self.assertEqual(args.lora_alpha, 64)
        self.assertEqual(args.lora_dropout, 0.1)

class TestTimeoutCallback(unittest.TestCase):
    def test_initialization(self):
        """TimeoutCallbackã®åˆæœŸåŒ–ã‚’ãƒ†ã‚¹ãƒˆ"""
        callback = TimeoutCallback(max_time_hours=2)
        self.assertEqual(callback.max_time_seconds, 7200)
        self.assertIsInstance(callback.start_time, float)
    
    @patch('time.time')
    def test_timeout_not_reached(self, mock_time):
        """ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæœªåˆ°é”ã®å ´åˆã‚’ãƒ†ã‚¹ãƒˆ"""
        mock_time.side_effect = [1000, 1000 + 3600]  # 1æ™‚é–“çµŒé
        callback = TimeoutCallback(max_time_hours=2)
        
        mock_control = MagicMock()
        mock_control.should_training_stop = False
        
        callback.on_step_end(None, None, mock_control)
        self.assertFalse(mock_control.should_training_stop)
    
    @patch('time.time')
    @patch('builtins.print')
    def test_timeout_reached(self, mock_print, mock_time):
        """ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆåˆ°é”ã®å ´åˆã‚’ãƒ†ã‚¹ãƒˆ"""
        mock_time.side_effect = [1000, 1000 + 10800]  # 3æ™‚é–“çµŒé
        callback = TimeoutCallback(max_time_hours=2)
        
        mock_control = MagicMock()
        mock_control.should_training_stop = False
        
        callback.on_step_end(None, None, mock_control)
        
        self.assertTrue(mock_control.should_training_stop)
        mock_print.assert_called_once_with("Time limit reached: 3.00 hours")

class TestSystemCompatibility(unittest.TestCase):
    """ã‚·ã‚¹ãƒ†ãƒ äº’æ›æ€§ã®ãƒ†ã‚¹ãƒˆ"""
    
    def test_windows_command_compatibility(self):
        """Windowsã‚³ãƒãƒ³ãƒ‰ã®äº’æ›æ€§ãƒ†ã‚¹ãƒˆ"""
        import platform
        
        if platform.system() == "Windows":
            # Windowsã§ã¯ rm ã‚³ãƒãƒ³ãƒ‰ãŒä½¿ãˆãªã„ã“ã¨ã‚’ç¢ºèª
            import subprocess
            result = subprocess.run("rm --help", shell=True, capture_output=True)
            self.assertNotEqual(result.returncode, 0, "rmã‚³ãƒãƒ³ãƒ‰ã¯Windowsã§ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“")
            
            # Platform detectionãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¢ºèª
            self.assertEqual(platform.system(), "Windows", "Windowsãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ãŒæ­£ã—ãæ¤œå‡ºã•ã‚Œã¾ã™")

class TestTrainLora(unittest.TestCase):
    def setUp(self):
        """ãƒ†ã‚¹ãƒˆå‰ã®å…±é€šã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        # ãƒ¢ãƒƒã‚¯åŒ–ã—ãŸç’°å¢ƒã§model2templateã‚’è¨­å®š
        self.model2template_patcher = patch.dict('sys.modules', {
            'utils.constants': MagicMock(model2template={'test_model': 'test_template'})
        })
        self.model2template_patcher.start()
        
    def tearDown(self):
        """ãƒ†ã‚¹ãƒˆå¾Œã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        self.model2template_patcher.stop()
    
    @patch.dict(os.environ, {'HF_TOKEN': 'test_token'})
    @patch('builtins.print')
    def test_train_lora_success(self, mock_print):
        """train_loraé–¢æ•°ã®æ­£å¸¸å®Ÿè¡Œã‚’ãƒ†ã‚¹ãƒˆï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        # Create training arguments
        training_args = LoraTrainingArguments(
            per_device_train_batch_size=4,
            gradient_accumulation_steps=2,
            num_train_epochs=5,
            lora_rank=32,
            lora_alpha=64,
            lora_dropout=0.1
        )
        
        # Call function
        train_lora("test_model", 2048, training_args)
        
        # Verify basic print statementsï¼ˆæ™‚é–“è¨ˆç®—ã¯é™¤å¤–ï¼‰
        expected_calls = [
            call("Starting training with test_model"),
            call("Training configuration: epochs=5, batch_size=4"),
            call("Starting training...")
        ]
        mock_print.assert_has_calls(expected_calls, any_order=False)
        
        # Training Completed ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå«ã¾ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆæ™‚é–“ã¯å•ã‚ãªã„ï¼‰
        print_calls = [str(call_obj) for call_obj in mock_print.call_args_list]
        completed_calls = [call for call in print_calls if "Training Completed" in call]
        self.assertTrue(len(completed_calls) > 0, "Training Completed ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå‡ºåŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    
    def test_train_lora_unsupported_model(self):
        """ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¹ãƒˆ"""
        training_args = LoraTrainingArguments(
            per_device_train_batch_size=4,
            gradient_accumulation_steps=2,
            num_train_epochs=5,
            lora_rank=32,
            lora_alpha=64,
            lora_dropout=0.1
        )
        
        # printæ–‡ã‚’ãƒ¢ãƒƒã‚¯åŒ–ã—ã¦ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã¿ã‚’ç¢ºèª
        with patch('builtins.print'):
            with self.assertRaises(AssertionError) as context:
                train_lora("unsupported_model", 2048, training_args)
            
            self.assertIn("model_id unsupported_model not supported", str(context.exception))

if __name__ == '__main__':
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ™‚ã®è©³ç´°è¨­å®š
    unittest.main(verbosity=2)